{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8670ab6-254f-4bbc-8074-91bd001f8725",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m builder \u001b[38;5;241m=\u001b[39m pyspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mSparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark://spark-master:7077\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.extensions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.delta.sql.DeltaSparkSessionExtension\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.catalog.spark_catalog\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.delta.catalog.DeltaCatalog\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.hadoop.fs.s3a.path.style.access\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.hadoop.fs.s3a.impl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.hadoop.fs.s3a.S3AFileSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mconfigure_spark_with_delta_pip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menableHiveSupport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:269\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:483\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    198\u001b[0m         master,\n\u001b[1;32m    199\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/context.py:417\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 417\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/java_gateway.py:106\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava gateway process exited before sending its port number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[1;32m    109\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"demo\").master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\",\"datalake\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\",\"datalake\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\",\"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51aa8c8-300d-4bde-97d8-f417e7fc19be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0b94591600>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e58ecb5b-f43c-4aaa-a694-f98440ff2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userBronze = spark.read.json('s3a://camada-bronze/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "186032a8-019d-4ed6-ac30-2f7ded8108e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userBronze.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e5e6fd3-fe3d-4eb2-9c3d-fa090137cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userSimple = df_userBronze.select('first_name','last_name','id','username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64a718ab-1c08-4b31-9de2-d2c2bab69b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userSimple.repartition(4).write.parquet('s3a://camada-prata/user',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50c927be-8e3f-4028-ae95-476dd7c989fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userPrata = spark.read.parquet('s3a://camada-prata/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a67c43c-bc4a-4a56-833c-983097c0fe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userPrata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd99690a-57ab-4bcb-a2b9-d074028f07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_userPrata.write.format('delta').save('s3a://camada-ouro/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "667f5968-7827-40fe-b6e9-0f163f305a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userDelta = DeltaTable.forPath(spark,'s3a://camada-ouro/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad1c8253-79c1-4542-aef1-b5f76407563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userDelta.toDF().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "825da206-73f7-4b6a-b99f-f859609bf2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delta.tables.DeltaTable"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_userDelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f96cdcca-908e-4d22-a701-7bca566db89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userDelta.alias('ouro') \\\n",
    "    .merge(df_userPrata.alias('prata'),\n",
    "    \"ouro.id = prata.id\") \\\n",
    "    .whenMatchedUpdate(set = {\"username\": col(\"prata.username\")}) \\\n",
    "    .whenNotMatchedInsert(values = {\"id\": col(\"prata.id\"),\"username\": col(\"prata.username\")}) \\\n",
    "    .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "efa114af-31a4-4a1b-ae71-4db2eee7841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_userDelta = DeltaTable.forPath(spark,'s3a://camada-ouro/user')\n",
    "df_userDelta.toDF().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cc0296d-cb66-4408-befd-e9dc071ac7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+----------------+\n",
      "|first_name|last_name|  id|        username|\n",
      "+----------+---------+----+----------------+\n",
      "|   Emanuel|    Marks| 202|   emanuel.marks|\n",
      "|    Samual|    Crist| 245|    samual.crist|\n",
      "|      null|     null| 251|     angelo.koss|\n",
      "|      null|     null| 358|    cyrus.casper|\n",
      "|     Ozell|  Pacocha| 391|   ozell.pacocha|\n",
      "|      null|     null| 801|       mason.rau|\n",
      "|    Tomika|     Mohr| 867|     tomika.mohr|\n",
      "|      Otto|     Kris| 931|       otto.kris|\n",
      "|      null|     null|1230|theodore.ritchie|\n",
      "|       Lou|  Watsica|1524|     lou.watsica|\n",
      "|      null|     null|1746|   horace.turner|\n",
      "|    Luanne|    Koepp|1801|    luanne.koepp|\n",
      "|      null|     null|2083|  mason.predovic|\n",
      "|      null|     null|2534|adalberto.dooley|\n",
      "|   Charlie|  Johnson|2572| charlie.johnson|\n",
      "|   Zenobia|   Parker|2837|  zenobia.parker|\n",
      "|      null|     null|2839|  jules.mitchell|\n",
      "|    Roxane|  Gerlach|2861|  roxane.gerlach|\n",
      "|    Colton| Franecki|2867| colton.franecki|\n",
      "|      null|     null|2869|    buford.olson|\n",
      "+----------+---------+----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_userDelta.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a877c31-09f0-46af-bd2b-04f720d19aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userSimple.createOrReplaceTempView('tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe751da3-1c5f-49c6-b3e0-9a2bd9c3d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = spark.sql('select * from tab where id > 7300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b97dad4-21ed-4d96-b230-d32b0516854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sql` not found.\n"
     ]
    }
   ],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ad10565-1f7b-4756-a36d-97436bd407fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method filter in module pyspark.sql.dataframe:\n",
      "\n",
      "filter(condition: 'ColumnOrName') -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Filters rows using the given condition.\n",
      "    \n",
      "    :func:`where` is an alias for :func:`filter`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    condition : :class:`Column` or str\n",
      "        a :class:`Column` of :class:`types.BooleanType`\n",
      "        or a string of SQL expression.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.filter(df.age > 3).collect()\n",
      "    [Row(age=5, name='Bob')]\n",
      "    >>> df.where(df.age == 2).collect()\n",
      "    [Row(age=2, name='Alice')]\n",
      "    \n",
      "    >>> df.filter(\"age > 3\").collect()\n",
      "    [Row(age=5, name='Bob')]\n",
      "    >>> df.where(\"age = 2\").collect()\n",
      "    [Row(age=2, name='Alice')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_test.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f32dc2e4-9a2b-480e-b435-07133b7c7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76575793-f1a9-455e-93fe-0116dbd88dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://random-data-api.com/api/v2/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3845e041-4b10-41ad-a5cd-836ab549e2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 7537,\n",
       " 'uid': '89c0ff87-d75c-4fbb-88ad-f4ff53f76abc',\n",
       " 'password': 'mFTXCrOS9H',\n",
       " 'first_name': 'Jamison',\n",
       " 'last_name': 'Fisher',\n",
       " 'username': 'jamison.fisher',\n",
       " 'email': 'jamison.fisher@email.com',\n",
       " 'avatar': 'https://robohash.org/quiaquirem.png?size=300x300&set=set1',\n",
       " 'gender': 'Agender',\n",
       " 'phone_number': '+1-758 1-521-477-3813',\n",
       " 'social_insurance_number': '776045551',\n",
       " 'date_of_birth': '1960-11-12',\n",
       " 'employment': {'title': 'Direct Consulting Coordinator',\n",
       "  'key_skill': 'Fast learner'},\n",
       " 'address': {'city': 'West Marva',\n",
       "  'street_name': 'Duane Gardens',\n",
       "  'street_address': '196 Pagac Via',\n",
       "  'zip_code': '61204-4737',\n",
       "  'state': 'Illinois',\n",
       "  'country': 'United States',\n",
       "  'coordinates': {'lat': 83.53003509882083, 'lng': -164.43744273559022}},\n",
       " 'credit_card': {'cc_number': '4335-8763-6109-2084'},\n",
       " 'subscription': {'plan': 'Basic',\n",
       "  'status': 'Pending',\n",
       "  'payment_method': 'Cheque',\n",
       "  'term': 'Monthly'}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3aae829e-65bb-40dd-9aee-d333046da083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = spark.read.json(spark.sparkContext.parallelize(r.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c50af2de-6062-4752-b849-661c99bf9de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     _corrupt_record|\n",
      "+--------------------+\n",
      "|                  id|\n",
      "|                 uid|\n",
      "|            password|\n",
      "|          first_name|\n",
      "|           last_name|\n",
      "|            username|\n",
      "|               email|\n",
      "|              avatar|\n",
      "|              gender|\n",
      "|        phone_number|\n",
      "|social_insurance_...|\n",
      "|       date_of_birth|\n",
      "|          employment|\n",
      "|             address|\n",
      "|         credit_card|\n",
      "|        subscription|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709278d7-359e-41c3-a1b4-5d9e12f56ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
